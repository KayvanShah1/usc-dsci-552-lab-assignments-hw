{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KayvanShah1/usc-dsci-552-lab-assignments-hw/blob/main/assignment-4/Assignment%204%20-%20Naive%20Bayes%20-%20solution-2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "610f3d52",
      "metadata": {
        "id": "610f3d52"
      },
      "source": [
        "# Assignment 4 Naive Bayes Classifier\n",
        "\n",
        "For this assignment you will implement a Naive Bayes Classifier that implements the SKlearn classifier API with `fit`, `predict` and `score` methods.\n",
        "\n",
        "The Naive Bayes Classifer takes as parameter the density function used in the likelihood calcuation: \n",
        "* `normal`: Normal density function\n",
        "* `knn`: K nearest neighbor density function\n",
        "\n",
        "Most of the code already has been written for you. You only need to fill in the missing part between \n",
        "```\n",
        "## Insert your code BEGIN\n",
        "\n",
        "## Insert your code END\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "57d846e0",
      "metadata": {
        "id": "57d846e0"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "560edeae",
      "metadata": {
        "id": "560edeae"
      },
      "outputs": [],
      "source": [
        "class NaiveBayesClassifier:\n",
        "    def __init__(self, likelihood='normal', k=None):\n",
        "        self.likelihood = likelihood\n",
        "        \n",
        "        # Let\n",
        "        #  K = number of unique classes\n",
        "        #  N = number of test instances\n",
        "        #  d = number of inputs (input dimensionality)\n",
        "\n",
        "        # Numpy array unique classes, shape = (K,)\n",
        "        self.classes = None\n",
        "        \n",
        "        # Numpy array of class priors, P(C), shape = (K,)\n",
        "        self.priors = None\n",
        "       \n",
        "        # Numpy array of likelihoods, P(x|C), shape = (N, K),\n",
        "        self.likelihoods = None\n",
        "\n",
        "        # Numpy array of posterior probabilities, P(C|x), shape = (N, K)\n",
        "        self.posteriors = None\n",
        "        \n",
        "        ## For the Guassian Density \n",
        "        # means, shape = (K, d)\n",
        "        self.avgs = None\n",
        "        # variances, shape = (K, d)\n",
        "        self.vars = None\n",
        "        \n",
        "        ## For the knn Density\n",
        "        # number of neighbors to use\n",
        "        self.k = k\n",
        "        # store training X\n",
        "        self.X_train = None\n",
        "        # store training y\n",
        "        self.y_train = None\n",
        "\n",
        "    \n",
        "    def generate_classes(self, y):\n",
        "        \"\"\"\n",
        "        Generate the classes based on y, and store in self.classes\n",
        "\n",
        "        :param y: array of class targets\n",
        "        \"\"\"\n",
        "        self.classes = np.unique(y)\n",
        "        \n",
        "    def generate_priors(self, y):\n",
        "        \"\"\"\n",
        "        Compute the prior probabilities and store self.priors\n",
        "\n",
        "        :param y: array of class targets\n",
        " \n",
        "        \"\"\"\n",
        "        ## Insert your code BEGIN\n",
        "        self.class_count_ = np.zeros(len(self.classes), dtype=np.float64)\n",
        "        classes = self.classes\n",
        "\n",
        "        for y_i in classes:\n",
        "            i = classes.searchsorted(y_i)\n",
        "            N_i = y[y==y_i].shape[0]\n",
        "            self.class_count_[i] += N_i\n",
        "\n",
        "        self.priors =  self.class_count_ / self.class_count_.sum()\n",
        "        ## Insert your code END\n",
        "    \n",
        "\n",
        "    def knn_density_function(self, x_train, x_predict): \n",
        "        \"\"\"\n",
        "        Implements k-nearest neighbor density estimate (Alpaydin Eq 8.8)\n",
        "\n",
        "        :param x_train 1d numpy array\n",
        "        :param x_predict 1d numpy array\n",
        "        :returns probabilities at x_prdict, shape = x_predict.shape\n",
        "        \"\"\"\n",
        "        # Find the distance to kth nearest neighbor\n",
        "        result = []\n",
        "        for x0 in x_predict:\n",
        "            dist = np.abs(x_train - x0)\n",
        "            index = np.argsort(dist)\n",
        "            result.append(dist[index[self.k - 1]])\n",
        "        dist_k = np.array(result)\n",
        "        \n",
        "        # Find the probability at x using knn density\n",
        "        # Note: Equation 8.8 may return probabilites greater than 1.\n",
        "        #       For probabilities greater than 1, set it equal to 1.\n",
        "        ## Insert your code BEGIN\n",
        "        N = x_predict.shape[0]\n",
        "        predict_proba = []\n",
        "        for i in range(N):\n",
        "            if dist_k[i]==0:\n",
        "                prob = 1\n",
        "            else:\n",
        "                prob = min(self.k/(2 * N * dist_k[i]), 1)\n",
        "            predict_proba.append(prob)\n",
        "        return np.array(predict_proba)\n",
        "        # Return ...\n",
        "        ## Insert your code END\n",
        "    \n",
        "    # Gaussian part\n",
        "    def generate_avgs(self, X, y):\n",
        "        \"\"\"\n",
        "        Return mean for each class and for each attribute\n",
        "        \"\"\"\n",
        "        ## Insert your code BEGIN\n",
        "        classes = self.classes\n",
        "        avgs = []\n",
        "        for y_i in self.classes:\n",
        "            X_i = X[y == y_i, :]\n",
        "            avgs.append(np.mean(X_i, axis=0).tolist())\n",
        "        return np.array(avgs)\n",
        "        ## Insert your code END\n",
        "    \n",
        "    def generate_vars(self, X, y):\n",
        "        \"\"\"\n",
        "        Return variance for each class and for each attribute\n",
        "        \"\"\"\n",
        "        ## Insert your code BEGIN\n",
        "        classes = self.classes\n",
        "        vars = []\n",
        "        for y_i in self.classes:\n",
        "            X_i = X[y == y_i, :]\n",
        "            vars.append(np.var(X_i, axis=0).tolist())\n",
        "        return np.array(vars)\n",
        "        ## Insert your code END\n",
        "    \n",
        "    ## Insert your code BEGIN\n",
        "    # Place any method you need here\n",
        "    # def ...\n",
        "    ## Insert your code END\n",
        "\n",
        "    def generate_guassian_likelihoods(self, X):\n",
        "        ## Insert your code BEGIN\n",
        "        log_likelihood = []\n",
        "        for i in range(np.size(self.classes)):\n",
        "            n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.vars[i, :]))\n",
        "            n_ij -= 0.5 * np.sum(((X - self.avgs[i, :]) ** 2) / (self.vars[i, :]), 1)\n",
        "            log_likelihood.append(n_ij)\n",
        "        return np.array(log_likelihood).T\n",
        "        ## Insert your code END\n",
        "\n",
        "    def generate_knn_likelihoods(self, X):\n",
        "        likelihoods = np.ones([len(self.classes), X.shape[0]])\n",
        "        for i, aclass in enumerate(self.classes):\n",
        "            index = self.y_train == aclass\n",
        "            for attr in range(X.shape[1]):\n",
        "                ## Insert your code BEGIN\n",
        "                likelihoods[i, :] *= self.knn_density_function(\n",
        "                    X[index, attr], X[:, attr]\n",
        "                )\n",
        "                ## Insert your code END\n",
        "        return np.log(likelihoods.T)\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        # define the classes with ascending order\n",
        "        self.generate_classes(y)\n",
        "        # compute the Priori probability\n",
        "        self.generate_priors(y)\n",
        "        \n",
        "        # different likelihood function\n",
        "        if self.likelihood == 'normal':\n",
        "            # calculate the avg and var based on X and y\n",
        "            self.avgs = self.generate_avgs(X, y)\n",
        "            self.vars = self.generate_vars(X, y)\n",
        "        elif self.likelihood == 'knn':\n",
        "            self.X_train = X\n",
        "            self.y_train = y\n",
        "        else:\n",
        "            raise ValueError('Invalid value for likelihood. Must be \"normal\" or \"knn\".')\n",
        "        return self\n",
        "\n",
        "    def generate_likelihoods(self, X):\n",
        "        \"\"\"\n",
        "        :param ndarray x \n",
        "        :returns probabilities at X (like X.shape[0] * Number of classes -> {Poss for each class} )\n",
        "        \"\"\"\n",
        "        # Gussian\n",
        "        if self.likelihood == \"normal\":\n",
        "            self.likelihoods = self.generate_guassian_likelihoods(X)\n",
        "        elif self.likelihood == \"knn\":\n",
        "            self.likelihoods = self.generate_knn_likelihoods(X)\n",
        "        else:\n",
        "            raise ValueError('Invalid value for likelihood Must be \"normal\" or \"knn\".')\n",
        "        return self.likelihoods\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        :param ndarray x \n",
        "        :returns prediction\n",
        "        \"\"\"\n",
        "        self.likelihoods = self.generate_likelihoods(X)\n",
        "        ## Insert your code BEGIN\n",
        "        self.posteriors = np.log(self.priors) + self.likelihoods\n",
        "        prediction = [self.classes[np.argmax(i)] for i in self.posteriors]\n",
        "        ## Insert your code END\n",
        "        return prediction\n",
        "\n",
        "    def score(self, X, y, sample_weight=None):\n",
        "        return accuracy_score(self.predict(X), y, sample_weight=sample_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "ab66369c",
      "metadata": {
        "id": "ab66369c"
      },
      "outputs": [],
      "source": [
        "iris = load_iris()\n",
        "x = iris['data']\n",
        "y = iris['target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "3e39f429",
      "metadata": {
        "id": "3e39f429",
        "outputId": "6d032a7a-405b-4562-9d58-3b453c3e7670",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.96\n"
          ]
        }
      ],
      "source": [
        "# Create an instance of the classifier with a normal likelihood distribution\n",
        "clf = NaiveBayesClassifier(likelihood='normal')\n",
        "\n",
        "# # Fit the classifier to the training data\n",
        "clf.fit(x, y)\n",
        "\n",
        "# # Use the classifier to make predictions on new data\n",
        "y_pred = clf.predict(x)\n",
        "\n",
        "# # Evaluate the accuracy of the classifier\n",
        "accuracy = clf.score(x, y)\n",
        "print('Accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "HH-u9noQSaTm",
      "metadata": {
        "id": "HH-u9noQSaTm",
        "outputId": "91e15eca-87b5-47a2-cfb7-289c2e19f32e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "means:\n",
            " [[5.006 3.428 1.462 0.246]\n",
            " [5.936 2.77  4.26  1.326]\n",
            " [6.588 2.974 5.552 2.026]]\n",
            "\n",
            "variances:\n",
            " [[0.122 0.141 0.03  0.011]\n",
            " [0.261 0.097 0.216 0.038]\n",
            " [0.396 0.102 0.298 0.074]]\n",
            "\n",
            "prior probability:\n",
            " [0.333 0.333 0.333]\n",
            "\n",
            "likelihoods:\n",
            "[[  2.161 -38.979 -55.744]\n",
            " [  1.519 -37.209 -55.192]\n",
            " [  1.268 -40.108 -57.749]\n",
            " [  1.198 -37.564 -55.283]\n",
            " [  2.111 -40.127 -56.697]]\n",
            "[[-252.68    -3.084   -4.495]\n",
            " [-234.161   -1.337   -4.185]\n",
            " [-284.931   -3.124   -2.948]\n",
            " [-163.146   -1.113  -11.486]\n",
            " [-247.01    -0.715   -3.712]]\n",
            "[[-5.863e+02 -2.613e+01 -2.646e+00]\n",
            " [-3.517e+02 -5.429e+00 -1.766e+00]\n",
            " [-5.074e+02 -1.634e+01 -7.383e-01]\n",
            " [-4.061e+02 -6.860e+00 -6.451e-01]\n",
            " [-5.012e+02 -1.577e+01 -4.852e-01]]\n",
            "\n",
            "posteriors:\n",
            "[[  1.063 -40.078 -56.843]\n",
            " [  0.421 -38.308 -56.29 ]\n",
            " [  0.169 -41.207 -58.848]\n",
            " [  0.099 -38.662 -56.382]\n",
            " [  1.012 -41.226 -57.796]]\n",
            "[[-253.779   -4.182   -5.594]\n",
            " [-235.259   -2.436   -5.283]\n",
            " [-286.029   -4.223   -4.047]\n",
            " [-164.245   -2.211  -12.585]\n",
            " [-248.109   -1.814   -4.811]]\n",
            "[[-587.428  -27.224   -3.745]\n",
            " [-352.765   -6.527   -2.864]\n",
            " [-508.479  -17.437   -1.837]\n",
            " [-407.196   -7.959   -1.744]\n",
            " [-502.286  -16.867   -1.584]]\n",
            "\n",
            "predictions:\n",
            "[0, 0, 0, 0, 0]\n",
            "[1, 1, 2, 1, 1]\n",
            "[2, 2, 2, 2, 2]\n"
          ]
        }
      ],
      "source": [
        "np.set_printoptions(precision=3)\n",
        "\n",
        "print(\"\\nmeans:\\n\", clf.avgs)\n",
        "\n",
        "print(\"\\nvariances:\\n\", clf.vars)\n",
        "\n",
        "print('\\nprior probability:\\n', clf.priors)\n",
        "\n",
        "print('\\nlikelihoods:')\n",
        "print(clf.likelihoods[:5, :])\n",
        "print(clf.likelihoods[50:55, :])\n",
        "print(clf.likelihoods[100:105, :])\n",
        "\n",
        "print('\\nposteriors:')\n",
        "print(clf.posteriors[:5, :])\n",
        "print(clf.posteriors[50:55, :])\n",
        "print(clf.posteriors[100:105, :])\n",
        "\n",
        "print('\\npredictions:')\n",
        "print(y_pred[:5])\n",
        "print(y_pred[50:55])\n",
        "print(y_pred[100:105])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "fab07350",
      "metadata": {
        "id": "fab07350",
        "outputId": "cab9d006-08ce-40e6-b18b-070c98a67ed8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.96\n"
          ]
        }
      ],
      "source": [
        "# Create an instance of the classifier with a normal likelihood distribution\n",
        "clf = NaiveBayesClassifier(likelihood='knn', k=3)\n",
        "\n",
        "# # Fit the classifier to the training data\n",
        "clf.fit(x, y)\n",
        "\n",
        "# # Use the classifier to make predictions on new data\n",
        "y_pred = clf.predict(x)\n",
        "\n",
        "# # Evaluate the accuracy of the classifier\n",
        "accuracy = clf.score(x, y)\n",
        "print('Accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "gat41ucYeEAU",
      "metadata": {
        "id": "gat41ucYeEAU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08fa8b47-3031-4e3c-f9d9-75a9351fd715"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prior probability:\n",
            " [0.333 0.333 0.333]\n",
            "\n",
            "likelihoods:\n",
            "[[  0.    -15.333 -17.093]\n",
            " [  0.    -11.932 -15.079]\n",
            " [ -2.303 -13.082 -15.331]\n",
            " [  0.    -13.264 -15.367]\n",
            " [  0.    -15.621 -17.941]]\n",
            "[[-15.176  -2.996  -7.601]\n",
            " [-14.584  -2.303  -5.704]\n",
            " [-15.256  -4.605  -2.303]\n",
            " [-16.489   0.    -13.775]\n",
            " [-17.748  -2.303  -5.298]]\n",
            "[[-17.808 -11.503  -2.303]\n",
            " [-16.543  -6.397   0.   ]\n",
            " [-16.118 -11.918  -4.605]\n",
            " [-17.305  -7.244  -2.303]\n",
            " [-15.591 -10.897   0.   ]]\n",
            "\n",
            "posteriors:\n",
            "[[ -1.099 -16.431 -18.192]\n",
            " [ -1.099 -13.03  -16.177]\n",
            " [ -3.401 -14.18  -16.429]\n",
            " [ -1.099 -14.362 -16.466]\n",
            " [ -1.099 -16.719 -19.039]]\n",
            "[[-16.275  -4.094  -8.7  ]\n",
            " [-15.682  -3.401  -6.802]\n",
            " [-16.355  -5.704  -3.401]\n",
            " [-17.588  -1.099 -14.873]\n",
            " [-18.847  -3.401  -6.397]]\n",
            "[[-18.906 -12.601  -3.401]\n",
            " [-17.642  -7.496  -1.099]\n",
            " [-17.216 -13.017  -5.704]\n",
            " [-18.403  -8.343  -3.401]\n",
            " [-16.69  -11.995  -1.099]]\n",
            "\n",
            "predictions:\n",
            "[0, 0, 0, 0, 0]\n",
            "[1, 1, 2, 1, 1]\n",
            "[2, 2, 2, 2, 2]\n"
          ]
        }
      ],
      "source": [
        "np.set_printoptions(precision=3)\n",
        "\n",
        "print('prior probability:\\n', clf.priors)\n",
        "\n",
        "print('\\nlikelihoods:')\n",
        "print(clf.likelihoods[:5, :])\n",
        "print(clf.likelihoods[50:55, :])\n",
        "print(clf.likelihoods[100:105, :])\n",
        "\n",
        "print('\\nposteriors:')\n",
        "print(clf.posteriors[:5, :])\n",
        "print(clf.posteriors[50:55, :])\n",
        "print(clf.posteriors[100:105, :])\n",
        "\n",
        "print('\\npredictions:')\n",
        "print(y_pred[:5])\n",
        "print(y_pred[50:55])\n",
        "print(y_pred[100:105])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q4znOnCUS9ZY"
      },
      "id": "q4znOnCUS9ZY",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}