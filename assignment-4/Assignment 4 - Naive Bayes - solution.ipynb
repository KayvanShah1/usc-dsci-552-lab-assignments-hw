{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KayvanShah1/usc-dsci-552-lab-assignments-hw/blob/main/assignment-4/Assignment%204%20-%20Naive%20Bayes%20-%20solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "610f3d52",
      "metadata": {
        "id": "610f3d52"
      },
      "source": [
        "# Assignment 4 Naive Bayes Classifier\n",
        "\n",
        "For this assignment you will implement a Naive Bayes Classifier that implements the SKlearn classifier API with `fit`, `predict` and `score` methods.\n",
        "\n",
        "The Naive Bayes Classifer takes as parameter the density function used in the likelihood calcuation: \n",
        "* `normal`: Normal density function\n",
        "* `knn`: K nearest neighbor density function\n",
        "\n",
        "Most of the code already has been written for you. You only need to fill in the missing part between \n",
        "```\n",
        "## Insert your code BEGIN\n",
        "\n",
        "## Insert your code END\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "57d846e0",
      "metadata": {
        "id": "57d846e0"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.stats import norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "560edeae",
      "metadata": {
        "id": "560edeae"
      },
      "outputs": [],
      "source": [
        "class NaiveBayesClassifier:\n",
        "    def __init__(self, likelihood='normal', k=None):\n",
        "        self.likelihood = likelihood\n",
        "        \n",
        "        # Let\n",
        "        #  K = number of unique classes\n",
        "        #  N = number of test instances\n",
        "        #  d = number of inputs (input dimensionality)\n",
        "\n",
        "        # Numpy array unique classes, shape = (K,)\n",
        "        self.classes = None\n",
        "        \n",
        "        # Numpy array of class priors, P(C), shape = (K,)\n",
        "        self.priors = None\n",
        "       \n",
        "        # Numpy array of likelihoods, P(x|C), shape = (N, K),\n",
        "        self.likelihoods = None\n",
        "\n",
        "        # Numpy array of posterior probabilities, P(C|x), shape = (N, K)\n",
        "        self.posteriors = None\n",
        "        \n",
        "        ## For the Guassian Density \n",
        "        # means, shape = (K, d)\n",
        "        self.avgs = None\n",
        "        # variances, shape = (K, d)\n",
        "        self.vars = None\n",
        "        \n",
        "        ## For the knn Density\n",
        "        # number of neighbors to use\n",
        "        self.k = k\n",
        "        # store training X\n",
        "        self.X_train = None\n",
        "        # store trainging y\n",
        "        self.y_train = None\n",
        "\n",
        "    \n",
        "    def generate_classes(self, y):\n",
        "        \"\"\"\n",
        "        Generate the classes based on y, and store in self.classes\n",
        "\n",
        "        :param y: array of class targets\n",
        "        \"\"\"\n",
        "        self.classes = np.unique(y)\n",
        "        \n",
        "    def generate_priors(self, y):\n",
        "        \"\"\"\n",
        "        Compute the prior probabilities and store self.priors\n",
        "\n",
        "        :param y: array of class targets\n",
        " \n",
        "        \"\"\"\n",
        "        ## Insert your code BEGIN\n",
        "        # self.priors = ...\n",
        "        \n",
        "        ## Insert your code END\n",
        "    \n",
        "\n",
        "    def knn_density_function(self, x_train, x_predict): \n",
        "        \"\"\"\n",
        "        Implements k-nearest neighbor density estimate (Alpaydin Eq 8.8)\n",
        "\n",
        "        :param x_train 1d numpy array\n",
        "        :param x_predict 1d numpy array\n",
        "        :returns probabilities at x_prdict, shape = x_predict.shape\n",
        "        \"\"\"\n",
        "        # Find the distance to kth nearest neighbor\n",
        "        result = []\n",
        "        for x0 in x_predict:\n",
        "            dist = np.abs(x_train - x0)\n",
        "            index = np.argsort(dist)\n",
        "            result.append(dist[index==self.k - 1][0])\n",
        "        dist_k = np.array(result)\n",
        "        \n",
        "        # Find the probability at x using knn density\n",
        "        # Note: Equation 8.8 may return probabilites greater than 1.\n",
        "        #       For probabilities greater than 1, set it equal to 1.\n",
        "        ## Insert your code BEGIN\n",
        "        \n",
        "        # Return ...\n",
        "        ## Insert your code END\n",
        "    \n",
        "    # Gaussian part\n",
        "    def generate_avgs(self, X, y):\n",
        "      \"\"\"\n",
        "      Return mean for each class and for each attribute\n",
        "      \"\"\"\n",
        "      ## Insert your code BEGIN\n",
        "      \n",
        "      ## Insert your code END\n",
        "    \n",
        "    def generate_vars(self, X, y):\n",
        "      \"\"\"\n",
        "      Return variance for each class and for each attribute\n",
        "      \"\"\"\n",
        "      ## Insert your code BEGIN\n",
        "      \n",
        "      ## Insert your code END\n",
        "    \n",
        "    ## Insert your code BEGIN\n",
        "    # Place any method you need here\n",
        "    # def ...\n",
        "\n",
        "    ## Insert your code END\n",
        "\n",
        "    def generate_guassian_likelihoods(self, X):\n",
        "        ## Insert your code BEGIN\n",
        "\n",
        "        ## Insert your code END\n",
        "\n",
        "    def generate_knn_likelihoods(self, X):\n",
        "      likelihoods = np.ones([len(self.classes), X.shape[0] ])\n",
        "        for i, aclass in enumerate(self.classes):\n",
        "            index = self.y_train == aclass\n",
        "            for attr in range(X.shape[1]):\n",
        "              ## Insert your code BEGIN\n",
        "\n",
        "              ## Insert your code END\n",
        "        return likelihood\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        # define the classes with ascending order\n",
        "        self.generate_classes(y)\n",
        "        # compute the Priori probability\n",
        "        self.generate_priors(y)\n",
        "        \n",
        "        # different likelihood function\n",
        "        if self.likelihood == 'normal':\n",
        "            # calculate the avg and var based on X and y\n",
        "            self.avgs = self.generate_avgs(X, y)\n",
        "            self.vars = self.generate_vars(X, y)\n",
        "        elif self.likelihood == 'knn':\n",
        "            self.X_train = X\n",
        "            self.y_train = y\n",
        "        else:\n",
        "            raise ValueError('Invalid value for likelihood. Must be \"normal\" or \"knn\".')\n",
        "        return self\n",
        "\n",
        "    def generate_likelihoods(self, X):\n",
        "        \"\"\"\n",
        "        :param ndarray x \n",
        "        :returns probabilities at X (like X.shape[0] * Number of classes -> {Poss for each class} )\n",
        "        \"\"\"\n",
        "        # Gussian\n",
        "        if self.likelihood == \"normal\":\n",
        "            self.likelihoods = self.generate_guassian_likelihoods(X)\n",
        "        elif self.likelihood == \"knn\":\n",
        "            self.likelihoods = self.generate_knn_likelihoods(X)\n",
        "        else:\n",
        "            raise ValueError('Invalid value for likelihood Must be \"normal\" or \"knn\".')\n",
        "        return self.likelihoods\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        :param ndarray x \n",
        "        :returns prediction\n",
        "        \"\"\"\n",
        "        self.likelihoods = self.generate_likelihoods(X)\n",
        "        ## Insert your code BEGIN\n",
        "        # self.posteriors = ...\n",
        "\n",
        "        ## Insert your code END\n",
        "        return prediction\n",
        "\n",
        "    def score(self, X, y, sample_weight=None):\n",
        "        return accuracy_score(self.predict(X), y, sample_weight=sample_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ab66369c",
      "metadata": {
        "id": "ab66369c"
      },
      "outputs": [],
      "source": [
        "iris = load_iris()\n",
        "x = iris['data']\n",
        "y = iris['target']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e39f429",
      "metadata": {
        "id": "3e39f429"
      },
      "outputs": [],
      "source": [
        "# Create an instance of the classifier with a normal likelihood distribution\n",
        "clf = NaiveBayesClassifier(likelihood='normal')\n",
        "\n",
        "# # Fit the classifier to the training data\n",
        "clf.fit(x, y)\n",
        "\n",
        "# # Use the classifier to make predictions on new data\n",
        "y_pred = clf.predict(x)\n",
        "\n",
        "# # Evaluate the accuracy of the classifier\n",
        "accuracy = clf.score(x, y)\n",
        "print('Accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HH-u9noQSaTm",
      "metadata": {
        "id": "HH-u9noQSaTm"
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(precision=3)\n",
        "\n",
        "print(\"\\nmeans:\\n\", clf.avgs)\n",
        "\n",
        "print(\"\\nvariances:\\n\", clf.vars)\n",
        "\n",
        "print('\\nprior probability:\\n', clf.priors)\n",
        "\n",
        "print('\\nlikelihoods:')\n",
        "print(clf.likelihoods[:5, :])\n",
        "print(clf.likelihoods[50:55, :])\n",
        "print(clf.likelihoods[100:105, :])\n",
        "\n",
        "print('\\nposteriors:')\n",
        "print(clf.posteriors[:5, :])\n",
        "print(clf.posteriors[50:55, :])\n",
        "print(clf.posteriors[100:105, :])\n",
        "\n",
        "print('\\npredictions:')\n",
        "print(y_pred[:5])\n",
        "print(y_pred[50:55])\n",
        "print(y_pred[100:105])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fab07350",
      "metadata": {
        "id": "fab07350"
      },
      "outputs": [],
      "source": [
        "# Create an instance of the classifier with a normal likelihood distribution\n",
        "clf = NaiveBayesClassifier(likelihood='knn', k=3)\n",
        "\n",
        "# # Fit the classifier to the training data\n",
        "clf.fit(x, y)\n",
        "\n",
        "# # Use the classifier to make predictions on new data\n",
        "y_pred = clf.predict(x)\n",
        "\n",
        "# # Evaluate the accuracy of the classifier\n",
        "accuracy = clf.score(x, y)\n",
        "print('Accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gat41ucYeEAU",
      "metadata": {
        "id": "gat41ucYeEAU"
      },
      "outputs": [],
      "source": [
        "np.set_printoptions(precision=3)\n",
        "\n",
        "print('prior probability:\\n', clf.priors)\n",
        "\n",
        "print('\\nlikelihoods:')\n",
        "print(clf.likelihoods[:5, :])\n",
        "print(clf.likelihoods[50:55, :])\n",
        "print(clf.likelihoods[100:105, :])\n",
        "\n",
        "print('\\nposteriors:')\n",
        "print(clf.posteriors[:5, :])\n",
        "print(clf.posteriors[50:55, :])\n",
        "print(clf.posteriors[100:105, :])\n",
        "\n",
        "print('\\npredictions:')\n",
        "print(y_pred[:5])\n",
        "print(y_pred[50:55])\n",
        "print(y_pred[100:105])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}