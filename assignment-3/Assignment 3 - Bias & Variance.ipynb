{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b755a204",
   "metadata": {
    "id": "b755a204"
   },
   "source": [
    "# Assignment 3:  Bias & Variance (60 points)\n",
    "## Due Thursday, Feburary 16, 2023 at 6PM\n",
    "**Turning the .ipynb notebook, and a viewable version of the notebook, such as html or pdf.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a646ec0",
   "metadata": {},
   "source": [
    "**This assignment aims to replicate the bias/variances figures 4.5 and 4.6 in section 4.7 of Alpaydin, deepening the understanding of bias and variance.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e092f3a",
   "metadata": {},
   "source": [
    "## Question one (20 points)\n",
    "**Replicate figures 4.5 in section 4.7 of Alpyadin 4th edition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388ec9a0",
   "metadata": {
    "id": "388ec9a0"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017bbb15",
   "metadata": {},
   "source": [
    "**The ground thruth function for the regression is f(x) = 3 cos(2x)**\n",
    "\n",
    "**Generate 100 sample datasets with f(x) + Gaussian white noise (N(0,1)). Each dataset will have 20 points randomly selected x from [0,5] with corresponding target points.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b9c231",
   "metadata": {
    "id": "e6b9c231"
   },
   "outputs": [],
   "source": [
    "# Ground truth target function\n",
    "def f(x):\n",
    "    return 3 * np.cos(1.3 * x)\n",
    "\n",
    "# seed\n",
    "np.random.seed(62)\n",
    "# x\n",
    "x = np.random.uniform(0.0, 5.0, [100, 20])\n",
    "x = np.sort(x)\n",
    "\n",
    "# Ground truth targets\n",
    "g = f(x)\n",
    "# Add white noise\n",
    "noisy = np.random.normal(0, 1, [100, 20])\n",
    "# y\n",
    "y = g + noisy\n",
    "\n",
    "# use linspace(0,5,100) as test set to plot the images\n",
    "x_test = np.linspace(0,5,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa80849d",
   "metadata": {},
   "source": [
    "<strong>TODO: Use the First 5 datasets to generate 4 plots.</strong>\n",
    " - Figure one: Function f(x) = 3 cos(2x) and one noisy dataset sampled from the function, namely \"Function, and data\".\n",
    " - Figure two: Generate five polynomial fits of degree ONE based on the first five datasets and name this figure with \"Order 1\"\n",
    " - Figure three: Generate five polynomial fits of degree THREE based on the first five datasets and name this figure with \"Order 3\"\n",
    " - Figure four: Generate five polynomial fits of degree FIVE based on the first five datasets and name this figure with \"Order 5\"\n",
    " - For figures two, three, and four, please add a dotted line as an average line for the five fits.\n",
    "  \n",
    "  \n",
    "<b> Please use x_test to plot all the model functions, not just the ground truth function. This will make all the higher polynomial models look smoother. </b>\n",
    "\n",
    "<br>\n",
    "\n",
    "<strong>Hint: You can use the Sklearnâ€™s PolynomialFeatures and LinearRegression. </storng>\n",
    "- https://scikit-learn.org/stable/modules/linear_model.html#polynomial-regression-extending-linear-models-with-basis-functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27365b35",
   "metadata": {
    "id": "27365b35"
   },
   "outputs": [],
   "source": [
    "# model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def linear_model_predict(X, Y, order):\n",
    "    # fit one polynomial model of degree `order`\n",
    "    ## Insert your code BEGIN\n",
    "\n",
    "    ## Insert your code END\n",
    "    return model\n",
    "\n",
    "def plot_figure(x, y, x_test, order):\n",
    "    # plot five curves corresponding to the polynomial of degree `order`\n",
    "    # plot the average of these five curves\n",
    "    ## Insert your code BEGIN\n",
    "\n",
    "    ## Insert your code END\n",
    "\n",
    "    \n",
    "# show the plots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 15))\n",
    "\n",
    "\n",
    "# figure one\n",
    "plt.subplot(2, 2, 1)\n",
    "## Insert your code BEGIN\n",
    "\n",
    "## Insert your code END\n",
    "\n",
    "# figure two\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.ylim(-5, 5)\n",
    "plot_figure(x, y, x_test, order=1)\n",
    "\n",
    "# figure three\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.ylim(-5, 5)\n",
    "plot_figure(x, y, x_test, order=3)\n",
    "\n",
    "# figure four\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.ylim(-5, 5)\n",
    "plot_figure(x, y, x_test, order=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c303ce",
   "metadata": {},
   "source": [
    "## Question 2 (40 points)\n",
    "\n",
    "**TODO: Generate Figure 4.6 from Alpaydin 4th Edition**\n",
    "\n",
    "**The x-axis is the order of polynomial model, from 1 to 5. the y-axis is the error. The plot should contain three curves: total error, bias error and variance error.**\n",
    "\n",
    "**Use all 100 dataset to compute the total error, bias error and variance error functions by using total error equation (4.36): $Ex[(E[r|x]-g(x))^2|x] = (E[r|x]) - E_X(g(x))^2 + E_X[(g(x)-E_X[g(x)])^2]$**\n",
    "\n",
    "**Evaluate each of the three error functions with 10 equally spaced values starting from 0 and ending at 5, i.e. np.linspace(0, 5, 10)**\n",
    "\n",
    "**TODO: For each of the five polynomial models, print the average predictions, $E_X[g(x)]$, at np.linspace(0, 5, 10)**\n",
    "\n",
    "**Hint: Average prediction at point x means computing the average value of the predictions of 100 models generated by 100 datasets. The point x should range from np.linspace(0, 5, 10)**\n",
    "\n",
    "\n",
    "**TODO: Generate and print a DataFrame with 5 rows, one for each order and 4 columns. The 4 columns are:**\n",
    " * **Order**\n",
    " * **Bias error**\n",
    " * **Variance error**\n",
    " * **Total error**\n",
    "\n",
    "\n",
    "**Hint: Average prediction at point x means computing the average value of the predictions of 100 models generated by 100 datasets. The point x should range from np.linspace(0, 5, 10)**\n",
    "\n",
    "**Hint: For bias error $(E[r|x]) - E_X(g(x))^2$, $E[r|x] = f(x)$ and $E_X[g(x)]$ is the average over 100 models from the 100 datasets. Then, you can approximate bias error by average over x in np.linspace(0, 5, 10) of $(E[r|x] - E_X[g(x)])2$.**\n",
    "\n",
    "**Hint: For For variance error, you need to have a nested loops (for each dataset and for  x in np.linespace(0, 5, 10))  to get the average variance error.**\n",
    "\n",
    "**Hint: The total error is the sum of bias error and variance error.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86673f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Insert your code BEGIN\n",
    "# Define any variables or methods that you need here\n",
    "\n",
    "## Insert your code END  \n",
    "\n",
    "def bias_error(avg_pred, x_eval):\n",
    "    # For each polynomial order, computes its bias error\n",
    "    # returns a list of length 5\n",
    "    five_bias = []\n",
    "    ## Insert your code BEGIN\n",
    "\n",
    "    ## Insert your code END        \n",
    "    return five_bias\n",
    "\n",
    "def variance_error(avg_pred, models_evals):\n",
    "    # For each polynomial order, computes its variance error\n",
    "    # returns a list of length 5\n",
    "    five_variance = []\n",
    "    ## Insert your code BEGIN\n",
    "\n",
    "    ## Insert your code END  \n",
    "    return five_variance\n",
    "\n",
    "\n",
    "# Fit 5 * 100 models, i.e. fit 100 models for each degree in range(1, 6).\n",
    "# The shape of models_list is (5, 100)\n",
    "models_list = []\n",
    "## Insert your code BEGIN\n",
    "\n",
    "## Insert your code END\n",
    "\n",
    "\n",
    "# create evaluation x data \n",
    "x_eval = np.linspace(0, 5, 10)\n",
    "\n",
    "# Evaluate each of the 5 * 100 models on `x_eval`\n",
    "# The shape of models_evals_list is (5,100,10) which is 5 degree with 100 models and each model predict the 10 x evaluation\n",
    "models_evals_list = []\n",
    "## Insert your code BEGIN\n",
    "\n",
    "## Insert your code END\n",
    "\n",
    "\n",
    "# For each degree compute the average predictiona at `x_eval`\n",
    "# The shape `ave_preds_list` isis (5,10) \n",
    "avg_preds_list = []\n",
    "## Insert your code BEGIN\n",
    "\n",
    "## Insert your code END\n",
    "\n",
    "\n",
    "bias_lst = bias_error(avg_preds_list, x_eval)\n",
    "\n",
    "variance_lst = variance_error(avg_preds_list, models_evals_list)\n",
    "\n",
    "total_error = [x + y for x, y in zip(bias_lst, variance_lst)]\n",
    "\n",
    "# show the plot\n",
    "x_points = [1,2,3,4,5]\n",
    "\n",
    "plt.plot(x_points, bias_lst, linestyle='dashed',label = \"Bias^2\", marker='o', markersize=10)\n",
    "plt.plot(x_points, variance_lst, linestyle='dashed', label = \"Variance\", marker='o', markersize=10)\n",
    "plt.plot(x_points, total_error, linestyle='solid', label = \"Error\", marker='o', markersize=10)\n",
    "plt.legend()\n",
    "plt.xlim(0.9, 5.1)\n",
    "plt.xticks(np.linspace(1, 5, 5))\n",
    "plt.xlabel(\"Order\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.title(\"Bias and Variance Trade-off\")\n",
    "# Display graph\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b8995c",
   "metadata": {
    "id": "27b8995c"
   },
   "outputs": [],
   "source": [
    "# Error DataFrame\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "error_df = pd.DataFrame({\n",
    "    'Order': range(1,6),\n",
    "    'Bias Error': bias_lst,\n",
    "    'Variance Error': variance_lst,\n",
    "    'Total Error': total_error\n",
    "})\n",
    "error_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845dbb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average predictions\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "pd.DataFrame(avg_preds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf0a844",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
